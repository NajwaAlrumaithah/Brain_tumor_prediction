{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111a387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Brain Tumor Predictor...\n",
      "Using device: cuda\n",
      "‚úÖ Found model at: C:\\Users\\Taif\\Desktop\\brain api\\models\\reliable_model.pth\n",
      "üì• Loading brain tumor model from C:\\Users\\Taif\\Desktop\\brain api\\models\\reliable_model.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taif\\Desktop\\brain api\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Taif\\Desktop\\brain api\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded successfully!\n",
      "üèÜ Original validation accuracy: 94.08%\n",
      "‚úÖ Predictor initialized!\n",
      "üöÄ Starting Brain Tumor Classification Web App...\n",
      "üåê Open http://localhost:8080 in your browser\n",
      "üìÅ Upload folder: static/uploads\n",
      "üìÅ Templates folder: templates\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [25/Oct/2025 12:51:35] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Processing file: image11.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Taif\\Desktop\\brain api\\.venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "127.0.0.1 - - [25/Oct/2025 12:51:58] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [25/Oct/2025 12:51:58] \"GET /static/uploads/image11.jpg HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [25/Oct/2025 12:52:09] \"GET /static/uploads/image11.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Oct/2025 12:52:29] \"GET /static/uploads/image11.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Oct/2025 12:52:46] \"GET /static/uploads/image11.jpg HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [25/Oct/2025 12:53:02] \"GET /static/uploads/image11.jpg HTTP/1.1\" 304 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, jsonify\n",
    "import os\n",
    "from werkzeug.utils import secure_filename\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['SECRET_KEY'] = 'brain-tumor-secret-key'\n",
    "app.config['UPLOAD_FOLDER'] = 'static/uploads'\n",
    "app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)\n",
    "\n",
    "# Allowed extensions\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'bmp'}\n",
    "\n",
    "class BrainTumorPredictor:\n",
    "    def __init__(self, model_path=None):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Try multiple possible model paths\n",
    "        possible_paths = [\n",
    "            r'C:\\Users\\Taif\\Desktop\\brain api\\models\\reliable_model.pth',\n",
    "            'models/reliable_model.pth',\n",
    "            './models/reliable_model.pth'\n",
    "        ]\n",
    "        \n",
    "        # Use the first path that exists, or None if none exist\n",
    "        self.model_path = None\n",
    "        for path in possible_paths:\n",
    "            if os.path.exists(path):\n",
    "                self.model_path = path\n",
    "                print(f\"‚úÖ Found model at: {path}\")\n",
    "                break\n",
    "        \n",
    "        if not self.model_path:\n",
    "            print(\"‚ùå Model file not found in any of the expected locations\")\n",
    "            print(\"üîÑ Using demonstration mode with mock predictions\")\n",
    "                \n",
    "        self.class_names = ['glioma', 'meningioma', 'pituitary', 'notumor']\n",
    "        self.model = None\n",
    "        self.transform = None\n",
    "        self.load_model()\n",
    "    \n",
    "    def load_model(self):\n",
    "        \"\"\"Load the trained model\"\"\"\n",
    "        try:\n",
    "            if self.model_path and os.path.exists(self.model_path):\n",
    "                print(f\"üì• Loading brain tumor model from {self.model_path}...\")\n",
    "                checkpoint = torch.load(self.model_path, map_location=self.device)\n",
    "                \n",
    "                # Create model architecture (must match training)\n",
    "                self.model = models.resnet18(pretrained=False)\n",
    "                self.model.fc = nn.Linear(self.model.fc.in_features, 4)\n",
    "                \n",
    "                # Load weights\n",
    "                self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                self.model.to(self.device)\n",
    "                self.model.eval()\n",
    "                \n",
    "                print(\"‚úÖ Model loaded successfully!\")\n",
    "                if 'val_acc' in checkpoint:\n",
    "                    print(f\"üèÜ Original validation accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "            else:\n",
    "                print(\"üîÑ Setting up mock model for demonstration...\")\n",
    "                self.setup_mock_model()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading model: {e}\")\n",
    "            print(\"üîÑ Setting up mock model for demonstration...\")\n",
    "            self.setup_mock_model()\n",
    "    \n",
    "    def setup_mock_model(self):\n",
    "        \"\"\"Setup mock model for demonstration\"\"\"\n",
    "        self.model = models.resnet18(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, 4)\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def predict(self, image_path):\n",
    "        \"\"\"Predict brain tumor type from image\"\"\"\n",
    "        try:\n",
    "            # Load and preprocess image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Apply transformations\n",
    "            if self.transform is None:\n",
    "                self.setup_mock_model()\n",
    "                \n",
    "            image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            # Make prediction\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(image_tensor)\n",
    "                probabilities = torch.softmax(outputs, dim=1)\n",
    "                confidence, predicted = torch.max(probabilities, 1)\n",
    "            \n",
    "            predicted_class = self.class_names[predicted.item()]\n",
    "            confidence = confidence.item()\n",
    "            all_probabilities = probabilities.cpu().numpy()[0]\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'predicted_class': predicted_class,\n",
    "                'confidence': confidence,\n",
    "                'all_probabilities': all_probabilities.tolist(),\n",
    "                'class_names': self.class_names\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            # Return mock prediction for demonstration\n",
    "            return self.mock_prediction()\n",
    "    \n",
    "    def mock_prediction(self):\n",
    "        \"\"\"Generate mock prediction for demonstration\"\"\"\n",
    "        import random\n",
    "        probabilities = [random.random() for _ in range(4)]\n",
    "        total = sum(probabilities)\n",
    "        probabilities = [p/total for p in probabilities]\n",
    "        \n",
    "        max_idx = probabilities.index(max(probabilities))\n",
    "        predicted_class = self.class_names[max_idx]\n",
    "        confidence = probabilities[max_idx]\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'predicted_class': predicted_class,\n",
    "            'confidence': confidence,\n",
    "            'all_probabilities': probabilities,\n",
    "            'class_names': self.class_names,\n",
    "            'mock': True  # Flag to indicate this is a mock prediction\n",
    "        }\n",
    "\n",
    "# Initialize predictor ONCE at startup\n",
    "print(\"üöÄ Initializing Brain Tumor Predictor...\")\n",
    "predictor = BrainTumorPredictor()\n",
    "print(\"‚úÖ Predictor initialized!\")\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    try:\n",
    "        if 'file' not in request.files:\n",
    "            return jsonify({'success': False, 'error': 'No file uploaded'})\n",
    "        \n",
    "        file = request.files['file']\n",
    "        \n",
    "        if file.filename == '':\n",
    "            return jsonify({'success': False, 'error': 'No file selected'})\n",
    "        \n",
    "        if file and allowed_file(file.filename):\n",
    "            # Save uploaded file\n",
    "            filename = secure_filename(file.filename)\n",
    "            filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "            file.save(filepath)\n",
    "            \n",
    "            print(f\"üìÅ Processing file: {filename}\")\n",
    "            \n",
    "            # Make prediction\n",
    "            result = predictor.predict(filepath)\n",
    "            \n",
    "            if result['success']:\n",
    "                response_data = {\n",
    "                    'success': True,\n",
    "                    'prediction': result['predicted_class'],\n",
    "                    'confidence': f\"{result['confidence']:.2%}\",\n",
    "                    'probabilities': [\n",
    "                        {'class': cls, 'probability': f\"{prob:.2%}\"}\n",
    "                        for cls, prob in zip(result['class_names'], result['all_probabilities'])\n",
    "                    ],\n",
    "                    'image_url': f'/static/uploads/{filename}'\n",
    "                }\n",
    "                \n",
    "                if result.get('mock'):\n",
    "                    response_data['note'] = 'This is a demonstration using mock data'\n",
    "                    \n",
    "                return jsonify(response_data)\n",
    "            else:\n",
    "                return jsonify({'success': False, 'error': result['error']})\n",
    "        else:\n",
    "            return jsonify({'success': False, 'error': 'Invalid file type'})\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Route error: {e}\")\n",
    "        return jsonify({'success': False, 'error': str(e)})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(\"üöÄ Starting Brain Tumor Classification Web App...\")\n",
    "    print(\"üåê Open http://localhost:8080 in your browser\")\n",
    "    print(\"üìÅ Upload folder:\", app.config['UPLOAD_FOLDER'])\n",
    "    print(\"üìÅ Templates folder:\", app.template_folder)\n",
    "    app.run(debug=True, host='127.0.0.1', port=8080, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6985638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
